---
title: "hw2"
output:
  html_document:
    toc: true
    toc_float: true
date: "2025-09-28"
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(janitor)
library(dplyr)
library(lubridate)
```

# Problem 1
## Clean_pm
```{r clean_pm}
pols = read_csv("./data/pols-month.csv")

pols = pols |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.name[month],
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) |>
  select(-day, -prez_gop, -prez_dem)
glimpse(pols)

```

## Clean_snp

```{r clean_snp}
snp = read_csv("./data/snp.csv")
snp = snp |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.name[month]
  ) |>
  select(year, month, close) |>
  arrange(year, match(month, month.name))
glimpse(snp)
```

## Unemployment clean and merge
``` {r}
# Tidy unemployment and merge all datasets
unemp = read_csv("./data/unemployment.csv") |>
  pivot_longer(cols = -Year, names_to = "month", values_to = "unemployment") |>
  mutate(
    month = month.name[match(month, month.abb)],  # convert Jan → January, etc.
    year = Year
  ) |>
  select(year, month, unemployment)

merged_df = pols |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemp, by = c("year", "month"))

glimpse(merged_df)
```

## descirption
The pols-month dataset has 822 rows and 9 variables covering the years 1947 to 2015. Key variables include year, month, counts of governors, senators, and representatives from each party, and an indicator for the sitting president’s party.

The snp dataset has 787 rows and 3 variables, with data spanning much of the 20th century into the early 2000s. The key variables are year, month, and the stock market closing price (close).

The unemployment dataset contains over 816 (68*12) monthly observations, with variables year, month, and the unemployment rate (unemployment).

Finally, the merged dataset joins these three sources into a single table of 822 rows and 11 variables, indexed by year and month. This combined dataset allows us to analyze relationships among political party , market performance, and unemployment across time.

# Problem 2

```{r import n clean}
# Clean Mr. Trash Wheel
mr_trash = read_excel(
  "./data/202509 Trash Wheel Collection Data.xlsx",
  sheet = "Mr. Trash Wheel",
  skip = 1
) |>
  janitor::clean_names() |> #remove caps
  filter(!is.na(dumpster)) |> # remove the na row
  mutate(
    year = as.character(year),
    month = as.character(month),
    sports_balls = as.integer(round(sports_balls, 0)),
    wheel = "Mr. Trash Wheel"
  ) |>
  select(-starts_with("x"))

# Clean Professor Trash Wheel
prof_trash = read_excel(
  "./data/202509 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",
  skip = 1
) |> # do the same as aboves but no sports balls
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    year = as.character(year),
    month = as.character(month),
    wheel = "Professor Trash Wheel"
  ) |>
  select(-starts_with("x"))

# Clean Gwynns
gwynnda_trash = read_excel(
  "./data/202509 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynns Falls Trash Wheel",
  skip = 1
) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> #same as above
  mutate(
    year = as.character(year),
    month = as.character(month),
    wheel = "Gwynns"
  ) |>
  select(-starts_with("x"))

```

## Combine all wheels
```{r}

trash_data = bind_rows(mr_trash, prof_trash, gwynnda_trash)
prof_total_weight = trash_data |>
  filter(wheel == "Professor Trash Wheel") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

gwynnda_cigs_june2022 = trash_data |>
  filter(wheel == "Gwynns", year == "2022", month == "June") |>
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE))

head(trash_data)
prof_total_weight
gwynnda_cigs_june2022
```

### description
The combined Trash Wheel dataset contains `r nrow(trash_data)` observations from three wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. Each row represents the contents of a single dumpster collected by one of the wheels, with key variables including the dumpster ID (`dumpster`), date of collection (`month`, `year`, and `date`), the weight of trash collected in tons (`weight_tons`), the number of plastic bottles (`plastic_bottles`), and the number of cigarette butts (`cigarette_butts`). For example, Professor Trash Wheel has collected a total of `r prof_total_weight$total_weight` tons of trash, while Gwynnda collected `r gwynnda_cigs_june2022$total_cigs` cigarette butts in June 2022. These data allow us to compare not only the total amount of waste collected across wheels but also the types of trash they intercept over time.


# Problem 3
```{r import and clean}
# The ZORI file from Zillow often has ID columns plus many monthly columns with dates as column names.
zori_raw = read_csv("./data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", guess_max = 30000)
print(names(zori_raw)[1:min(30, length(names(zori_raw)))])
```
## tidy
```{r tidy}
zori = zori_raw |> 
  janitor::clean_names()

# Identify date columns after clean_names() (they all start with "x20")
date_cols = names(zori)[str_detect(names(zori), "^x20")]

# Pivot longer
zori_long = zori |>
  pivot_longer(
    cols = all_of(date_cols),
    names_to = "date_raw",
    values_to = "zori"
  ) |>
  mutate(
    # Remove the "x" prefix and underscores from date
    date = str_remove(date_raw, "^x"),
    date = ymd(str_replace_all(date, "_", "-")),
    year = year(date),
    month = month(date, label = TRUE, abbr = FALSE)
  ) |>
  filter(!is.na(date), !is.na(zori)) |>
  select(region_id, size_rank, region_name, region_type, state_name, state,
         city, metro, county_name, date, year, month, zori)
glimpse(zori_long)
```
```{r cleanzipcode}
zip_lookup = read_csv("./data/Zip Codes.csv") |> 
  janitor::clean_names() |>
  #rename(zip_code = zipcode) |> 
  mutate(
    zip = str_pad(as.character(zip_code), 5, pad = "0")  # standardized zip
  ) |>
  distinct(zip, .keep_all = TRUE)
```

```{r Merge}

zori_long = zori_long |>
  mutate(
    zip = str_pad(as.character(region_name), 5, pad = "0")  # create proper zip
  )

#merge
zori_final = zori_long |>
  left_join(zip_lookup, by = "zip") |>
  arrange(zip, date)
glimpse(zori_final)
```
### summary_and_analysis
```{r summary_and_analysis}

cat("Total", nrow(zori_final), "\n")
cat("Unique ZIP codes:", length(unique(zori_final$zip)), "\n")
cat("Unique neighborhoods:", length(unique(na.omit(zori_final$neighborhood))), "\n")

missing_zips = setdiff(zip_lookup$zip, zori_final$zip)
cat("zipcodes missing from Zillow data:", length(missing_zips), "\n")
#10 samples

head(missing_zips, 10) 

# comparison between 2020 and 2021
covid_change = zori_final |>
  filter(month == "January", year %in% c(2020, 2021)) |>
  select(zip, borough = county, neighborhood, year, zori) |>
  pivot_wider(names_from = year, values_from = zori, names_prefix = "year_") |>
  mutate(change = year_2021 - year_2020) |>
  arrange(change)  # sort by largest drop

top10_drops = covid_change |> 
  slice(1:10)

top10_drops
```